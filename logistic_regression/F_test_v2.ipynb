{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'v1_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17292/3684260134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mv1_model\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2_model\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'v1_model'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Credit to GitHub user Jaimin09\n",
    "Link: https://github.com/Jaimin09/Coding-Lane-Assets/tree/main/Logistic%20Regression%20in%20Python%20from%20Scratch\n",
    "Last accessed: 28/10/2021\n",
    "'''\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import scipy\n",
    "import v1_model as v1\n",
    "import v2_model as v2\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List containing medals earned for each athlete  \n",
    "Y_list = ['MedalEarned']\n",
    "\n",
    "# ! Get dataset\n",
    "filepath = 'Datasets/expert_data.csv' # Data for Specialized athletes i.e. competing in one sport\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.reset_index() # Resets index for dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and set seed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights, data  and probability predictions for v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of variables we are interested in \n",
    "X_list_v1 = ['Height',\n",
    "             'Weight',\n",
    "             'Age']\n",
    "\n",
    "# Import model weights after v1_model has been run \n",
    "W_array = np.genfromtxt('Parameters/W.csv', delimiter=',')# Len of array is equal to iterations\n",
    "B_array = np.genfromtxt('Parameters/B.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce weight for model\n",
    "def ProduceWeights(df, W, B, X_list):\n",
    "\n",
    "    # Get data for model\n",
    "    X_model_df = df[X_list] # Dataframe contains X_list columns \n",
    "    Y_model_df = df[Y_list]\n",
    "    \n",
    "    X_array, Y_array = v1.Reshape(X_model_df, Y_model_df) # Drops ID and transforms each column to a numpy array\n",
    "\n",
    "    # Get model guesses \n",
    "    \n",
    "    # Use dot product on weights and the variable values for each athlete i.e. Ath1 = w1*var1 + w2*var2(..) + B\n",
    "    lin_func = np.dot(W.T, X_array) + B\n",
    "    \n",
    "    # Use linear expression in sigmoid function to get model guess for each athlete \n",
    "    sf = v1.Sigmoid(lin_func) \n",
    "    \n",
    "    return sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F test loop v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate model predictions in two cases. \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "# Append model guesses to lists dependent on  the number of variables i.e. 4 variables creates a list of 4 arrays. \n",
    "\n",
    "def f_test_loop_v1(df, W, B, X_list):\n",
    "    \n",
    "    # Store model guesses with weights unchanged, and create empty list to store model prediction with weights changed\n",
    "    pred_prob_result_list = []\n",
    "    pred_prob = ProduceWeights(df, W, B, X_list)\n",
    "    \n",
    "    for index, element in enumerate(X_list):\n",
    "        \n",
    "        # Print output for each iteration\n",
    "        print(f'The current index is {index}')\n",
    "        print(f'The current element is {element}')\n",
    "        \n",
    "        # Change weights back to values found in W\n",
    "        W_test = copy.deepcopy(W)\n",
    "        \n",
    "        W_test[index] = 0 # index weight set to 0\n",
    "        \n",
    "        # Get a list of model guesses where weights are changed\n",
    "        pred_prob_result = ProduceWeights(df, W_test, B, X_list)\n",
    "        #print(pred_prob_result)\n",
    "        \n",
    "        # Append array of model guesses to list \n",
    "        pred_prob_result_list.append(pred_prob_result)\n",
    "    \n",
    "    return pred_prob, pred_prob_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first weight in CSV file of weights \n",
    "W_par = np.array([W_array[0][0], W_array[1][0], W_array[2][0]], ndmin= 0)\n",
    "B_par = B_array[0]\n",
    "\n",
    "# Create list of arrays of model guesses \n",
    "pred_prob_v1, pred_prob_result_list_v1 = f_test_loop_v1(df, W_par, B_par, X_list_v1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights, data  and probability predictions for v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list_v2 = ['PreviousMedals', 'NOC_advantage', 'Height_div_avg', 'Weight_div_avg', 'Age_div_avg']\n",
    "#'PreviousMedals', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run v2_model\n",
    "cop = 0.6\n",
    "W, B, val_acc, val_occ_dic, X_val, Y_val = v2.RunModel(df, X_list_v2, Y_list, cop, iterations= 80000, l_rate= 0.0223)\n",
    "sf = v2.PredProb(X_val, W, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F test loop v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model predictions in two cases. \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "# Append model guesses to lists dependent on  the number of variables i.e. 4 variables creates a list of 4 arrays. \n",
    "\n",
    "def f_test_loop_v2(sf, W, B, X_val, X_list):\n",
    "    \n",
    "    # Store model guesses with weights unchanged, and create empty list to store model prediction with weights changed\n",
    "    pred_prob_result_list = []\n",
    "    \n",
    "    for index, element in enumerate(X_list):\n",
    "        \n",
    "        # Print output for each iteration\n",
    "        print(f'The current index is {index}')\n",
    "        print(f'The current element is {element}')\n",
    "        \n",
    "        # Change weights back to values found in W\n",
    "        W_test = copy.deepcopy(W)\n",
    "        \n",
    "        W_test[index] = 0 # index weight set to 0\n",
    "        \n",
    "        # Get a list of model guesses where weights are changed\n",
    "        pred_prob_result = v2.PredProb(X_val, W_test, B)\n",
    "        #print(pred_prob_result)\n",
    "        \n",
    "        # Append array of model guesses to list \n",
    "        pred_prob_result_list.append(pred_prob_result)\n",
    "    \n",
    "    return pred_prob_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_prob_result_list_v2 = f_test_loop_v2(sf, W, B, X_val, X_list_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality plot v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### TO DO  \n",
    "\n",
    "def dist_plot_v1(my_array):\n",
    "    \n",
    "    # Create displots for elements in probablity array \n",
    "    \n",
    "    # Check whether it is an array or an array of arrays\n",
    "    if my_array[0][0] >= 0: \n",
    "        for i, element in enumerate(my_array):\n",
    "            sns.displot(my_array[i])\n",
    "    else:\n",
    "        sns.displot(my_array)\n",
    "\n",
    "#dist_plot(pred_prob_v1)\n",
    "        \n",
    "#sns.displot(pred_prob_v1)\n",
    "#sns.displot(pred_prob_result_list_v1)\n",
    "\n",
    "# Get qqplot \n",
    "#fig = plt.figure()\n",
    "#res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "pred_prob_result_list_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality plot v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_plot_v1(pred_prob_result_list_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# F-test: https://link.springer.com/book/10.1007%2F978-3-319-46162-5 \n",
    "# Code adapted from: https://www.statology.org/f-test-python/\n",
    "\n",
    "# F test arrays of model guesses \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "\n",
    "def f_test(sig_0_probabilities,sig_1_probabilities, X_list):\n",
    "    f_test_list = []\n",
    "    \n",
    "    for i in range(len(sig_1_probabilities)):\n",
    "        f = np.var(sig_0_probabilities, ddof=1)/np.var(sig_1_probabilities[i], ddof=1) #calculate F test statistic \n",
    "        dfn = sig_0_probabilities.size-1 #define degrees of freedom numerator \n",
    "        dfd = sig_1_probabilities[i].size-1 #define degrees of freedom denominator \n",
    "        p = 1-scipy.stats.f.cdf(f, dfn, dfd) #find p-value of F test statistic\n",
    "        f_test_list.append(p)\n",
    "        \n",
    "        # Print current variable and p value \n",
    "        print(f'The current variable is: {X_list[i]}\\nThe current p-value is: {p}')\n",
    "        \n",
    "        # Define alpha and print conclusion of hypothesis test \n",
    "        if p <= 0.05:\n",
    "            print(f\"null hypothesis is rejected: p-value = {p}.\\nThe probablity of the two distributions' variance being equal is low.\\nThe variable is likely to impact model output.\\n\")\n",
    "        else:\n",
    "            print(f\"null hypothesis cannot be rejected: p-value = {p}.\\nThe probablity of the two distributions' variance being equal is high.\\nThe variable is unlikely to impact model output.\\n\") \n",
    "    \n",
    "    return f_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_test_list_v1 = f_test(pred_prob_v1, pred_prob_result_list_v1, X_list_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test_list_v2 = f_test(sf, pred_prob_result_list_v2, X_list_v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
